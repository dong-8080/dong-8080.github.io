<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="wd"><title>Python爬虫笔记 · Dong</title><meta name="description" content="[toc]
基础知识爬虫：模拟客户端发送网络请求，获取响应，按照规则提取数据的程序
Get与Post的区别

Post安全：传输过程中Get将数据放在请求的URL中，Post所有操作对用户不可见，可用作注册登录。
Post数据量大：Get受URL长度限制传送的数据量较小，Post传送数据量大，可用于"><meta name="keywords" content="wd, dong, dong-8080, dong1024"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">Dong</a></h3><div class="description"><p><b>人若志趣不远，心不在焉，虽学不成。</b></p></div></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/dong-8080"><i class="fa fa-github"></i></a></li><li><a href="mailto:dong1024mail@163.com"><i class="fa fa-envelope"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2017 - 2021 </span><i class="fa fa-star"></i><span> wd</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div><div class="beian"><a href="http://www.beian.miit.gov.cn/" target="_blank">粤ICP备15011643号</a><span style="height:10px;margin-left: 10px;">|</span><img src="/images/gongan.png" style="height:10px;margin-left: 10px;position: relative;top: 1px;"><span style="margin-left: 2px;">粤公网安备 44030402003967号</span></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li><li><a href="/guestbook">留言</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Python爬虫笔记</a></h3></div><div class="post-content"><p>[toc]</p>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p><strong>爬虫</strong>：模拟客户端发送网络请求，获取响应，按照规则提取数据的程序</p>
<p><strong>Get与Post的区别</strong></p>
<ul>
<li>Post安全：传输过程中Get将数据放在请求的URL中，Post所有操作对用户不可见，可用作注册登录。</li>
<li>Post数据量大：Get受URL长度限制传送的数据量较小，Post传送数据量大，可用于传输大文件。</li>
</ul>
<p>###学习步骤</p>
<ul>
<li>python语法知识</li>
<li>Python中的内置库urllib，http等，用于下载网页</li>
<li>正则表达式re、BeautifulSoup(bs4)、Xpath(lxml)等网页解析工具</li>
<li>简单网站的爬取，了解爬取数据过程</li>
<li>了解爬虫的反爬机制，header、robot、时间间隔、代理IP、隐含字段等</li>
<li>特殊网站的爬取，解决登录、Cookie、动态网页问题</li>
<li>爬虫与数据库结合，将爬取数据进行存储</li>
<li>应用Python多线程、多进程进行爬取，提高效率</li>
<li>学习爬虫框架，Scrapy、PySpider等</li>
<li>分布式爬虫解决数据量庞大的需求</li>
</ul>
<h3 id="python内置urllib库"><a href="#python内置urllib库" class="headerlink" title="python内置urllib库"></a>python内置urllib库</h3><p>urllib是python的内置库，能够完成向服务器发出请求并获取网页的功能。</p>
<p>python3中将urllib与urllib2整合为唯一urlib，分成以下模块</p>
<ul>
<li><code>urllib.request</code> 用于打开和读取url，最重要</li>
<li><code>uellib.error</code> 用于处理request引起的异常</li>
<li><code>urllib.parse</code> 用于解析URL</li>
<li><code>urllib.roborparser</code> 用于解析robots.txt文件</li>
</ul>
<p><a target="_blank" rel="noopener" href='https://blog.csdn.net/jiduochou963/article/details/87564467'>关于python3与python2对于urllib的区别</a></p>
<p><strong>request的使用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">response=urllib.request.urlopen(<span class="string">&#x27;http://baidu.com&#x27;</span>)</span><br><span class="line">result=response.read()	<span class="comment">#因编码问题产生的乱码，使用response.read().decode(&#x27;utf-8&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>(result)			<span class="comment">#打印得到的html网页</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>urlopen方法</p>
<p>urlopen是request中的一个方法，作用是打开一个url，常用参数：</p>
<ul>
<li><strong>url</strong>：url网址</li>
<li><strong>data</strong>：如果添加data参数则为post请求，默认无data参数，为get请求</li>
<li><strong>timeout</strong>：超时时间</li>
</ul>
<p>urlopen会返回一个类文件对象，可以对该对象进行各种操作</p>
<ul>
<li>**read()**：读取html</li>
<li>**geturl()**：返回url，用于看是否有重定向</li>
<li>**info()**：返回元信息，如HTTP中的headers</li>
<li>**getcode()**：返回HTTP状态码</li>
</ul>
<p>urliopen的参数也可以是一个Request对象</p>
</li>
<li><p>Request类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Request</span>:</span>	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, url, data=<span class="literal">None</span>, headers=&#123;&#125;,</span></span></span><br><span class="line"><span class="params"><span class="function">             origin_req_host=<span class="literal">None</span>, unverifiable=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">             method=<span class="literal">None</span></span>):</span>	</span><br></pre></td></tr></table></figure>

<p>Request是一个类，初始化中包括请求需要的各种参数：</p>
<ul>
<li><p>url、data与urlopen中作用相同。</p>
</li>
<li><p>headers是HTTP请求的报文信息，可以让爬虫伪装成浏览器，主要是User_Agent，从浏览器复制即可。</p>
<p>使用Request</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line">response = urllib.request.Request(<span class="string">&#x27;http://python.org/&#x27;</span>, headers=headers)</span><br><span class="line">html = urllib.request.urlopen(response)</span><br><span class="line">result = html.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>error的使用</strong></p>
<p>error属性里包括了两个重要的exception类，URLError类和HTTPError类</p>
<ul>
<li><p>URLError类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, reason, filename=<span class="literal">None</span></span>):</span></span><br><span class="line">    self.args = reason,</span><br><span class="line">    self.reason = reason</span><br><span class="line">    <span class="keyword">if</span> filename <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        self.filename = filename</span><br></pre></td></tr></table></figure>

<p>URLError类是OSError的子类，没有自己的行为，但可以作为error里面所有其他类型的积累使用</p>
<p>URLError类初始化定义了reason参数，当使用URLError类的对象时，可以查看错误的reason</p>
</li>
<li><p>HTTPError类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, url, code, msg, hdrs, fp</span>):</span></span><br><span class="line">    self.code = code</span><br><span class="line">    self.msg = msg</span><br><span class="line">    self.hdrs = hdrs</span><br><span class="line">    self.fp = fp</span><br><span class="line">    self.filename = url</span><br></pre></td></tr></table></figure>

<p>HTTPError是URLError的子类，当HTTP发生错误时抛出HTTPError</p>
<p>使用HTTPError类的对象时，可以查看状态码，headers等</p>
</li>
</ul>
<p>使用两类exception的例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    headers = &#123;<span class="string">&#x27;User_Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (X11; Ubuntu; </span></span><br><span class="line"><span class="string">                Linux x86_64; rv:57.0) Gecko/20100101 </span></span><br><span class="line"><span class="string">                Firefox/57.0&#x27;</span>&#125;</span><br><span class="line">    response = urllib.request.Request(<span class="string">&#x27;http://python.org/&#x27;</span>, headers=headers)</span><br><span class="line">    html = urllib.request.urlopen(response)</span><br><span class="line">    result = html.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(e, <span class="string">&#x27;reason&#x27;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;错误原因是&#x27;</span> + <span class="built_in">str</span>(e.reason))</span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(e, <span class="string">&#x27;code&#x27;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;错误状态码是&#x27;</span> + <span class="built_in">str</span>(e.code))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;请求成功通过。&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><strong>设置headers</strong></p>
<p>有些网站会对请求进行识别，那么在headers中添加属性将爬虫伪装成浏览器。常用属性：</p>
<p><strong>User_agent</strong>：请求身份，从浏览器中Request Headers复制即可</p>
<p><strong>Referer</strong>：请求的来源，可以添加为网站</p>
<p><strong>Proxy（代理）设置</strong></p>
<p>有些网站会检测某一段时间某个IP的访问次数，如果访问次数过多会禁止访问。可以设置代理服务器帮助工作，没隔一段时间更换一个代理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用request包中的ProxyHandler类的对象与build_opener方法来创建opener，使用opener的open()方法来打开一个url，相当于urlopen()</span></span><br><span class="line">proxy=&#123;<span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;115.193.101.21:61234&#x27;</span>&#125;</span><br><span class="line">proxy_handler=urllib.request.ProxyHandler(proxy)</span><br><span class="line">opener=urllib.request.build_opener(proxy_hander)</span><br><span class="line">response=opener.<span class="built_in">open</span>(request)</span><br></pre></td></tr></table></figure>

<p>代理ip可以在下列网站找到</p>
<p><a target="_blank" rel="noopener" href="http://www.xicidaili.com/">http://www.xicidaili.com/</a>   <a target="_blank" rel="noopener" href="http://www.66ip.cn/">http://www.66ip.cn/</a>    </p>
<p><a target="_blank" rel="noopener" href="http://www.mimiip.com/gngao/">http://www.mimiip.com/gngao/</a>    <a target="_blank" rel="noopener" href="http://www.kuaidaili.com/">http://www.kuaidaili.com/</a></p>
<h4 id="requests库"><a href="#requests库" class="headerlink" title="requests库"></a>requests库</h4><p>requests是一个用户处理URL资源的第三方库，简化了urllib的操作</p>
<p><a target="_blank" rel="noopener" href='https://requests.readthedocs.io/en/master/user/quickstart/#response-content'>官网文档</a></p>
<p><strong>发送请求</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">r = requests.get(<span class="string">&#x27;https://api.github.com/events&#x27;</span>)</span><br><span class="line">r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data = &#123;<span class="string">&#x27;key&#x27;</span>:<span class="string">&#x27;value&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>

<p><strong>带参数的Get请求</strong></p>
<p>使用params关键字参数，会将字典中的内容拼接为带参数的url，还可以将列表作为value</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">payload = &#123;<span class="string">&#x27;key1&#x27;</span>: <span class="string">&#x27;value1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>: <span class="string">&#x27;value2&#x27;</span>&#125;</span><br><span class="line">r = requests.get(<span class="string">&quot;http://httpbin.org/get&quot;</span>, params=payload)</span><br></pre></td></tr></table></figure>

<p><strong>带参数的Post请求</strong></p>
<p>通常，只需要传递字典形式的数据即可:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">payload = &#123;<span class="string">&#x27;key1&#x27;</span>: <span class="string">&#x27;value1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>: <span class="string">&#x27;value2&#x27;</span>&#125;</span><br><span class="line">r = requests.post(<span class="string">&quot;http://httpbin.org/post&quot;</span>, data=payload)</span><br></pre></td></tr></table></figure>

<p>还可以为 <code>data</code> 参数传入一个元组列表。在表单中多个元素使用同一 key 的时候，这种方式尤其有效：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">payload = ((<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;value1&#x27;</span>), (<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;value2&#x27;</span>))</span><br><span class="line">r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data=payload)</span><br></pre></td></tr></table></figure>

<p><strong>响应内容</strong></p>
<ul>
<li><p>文本响应内容<strong>text</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://api.github.com/events&#x27;</span>)</span><br><span class="line">r.text  <span class="comment"># 得到服务器响应内容</span></span><br></pre></td></tr></table></figure>

<p>Requests会自动解码，若解码方式不当会出现乱码，可指定解码方式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://api.github.com/events&#x27;</span>)</span><br><span class="line">r.encoding=<span class="string">&#x27;utf-8&#x27;</span>	<span class="comment"># 指定解码方式</span></span><br><span class="line">r.text  </span><br></pre></td></tr></table></figure></li>
<li><p>二进制响应内容<strong>content</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r.content 				<span class="comment">#会得到二进制响应内容 b&#x27;something&#x27;</span></span><br><span class="line">r.content.decode() 		<span class="comment"># 二进制解码</span></span><br><span class="line">r.content.decode(<span class="string">&#x27;gbk&#x27;</span>) <span class="comment"># 指定二进制解码格式</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>Json响应内容</strong></p>
<p>requests中内置JSON解码器来处理JSON内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">&#x27;https://api.github.com/events&#x27;</span>)</span><br><span class="line">r.json()</span><br><span class="line"><span class="comment"># [&#123;u&#x27;repository&#x27;: &#123;u&#x27;open_issues&#x27;: 0, u&#x27;url&#x27;: &#x27;https://github.com/...</span></span><br></pre></td></tr></table></figure>

<p>如果解码失败，会抛出异常</p>
<p>解码成功不意味着响应成功，需要再根据响应内容判断，使用<code>r.status_code</code>或<code>r.raise_for_status()</code></p>
<p>成功响应状态码<code>200</code>或<code>requests.codes.ok</code></p>
<p>如果发送了错误请求，可以使用```Response.raise_for_status``抛出异常</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bad_r = requests.get(<span class="string">&#x27;http://httpbin.org/status/404&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bad_r.status_code</span><br><span class="line"><span class="number">404</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bad_r.raise_for_status()</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;requests/models.py&quot;</span>, line <span class="number">832</span>, <span class="keyword">in</span> raise_for_status</span><br><span class="line">    <span class="keyword">raise</span> http_error</span><br><span class="line">requests.exceptions.HTTPError: <span class="number">404</span> Client Error</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>定制请求头</strong></p>
<p>只需要传递<strong>dict</strong>给<strong>headers</strong>即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;my-app/0.0.1&#x27;</span>&#125;</span><br><span class="line">r = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure>

<p><strong>超时</strong></p>
<figure class="highlight plaintext"><figcaption><span>`timeout` 并不是整个下载响应的时间限制，而是如果服务器在 `timeout` 秒内没有应答，将会引发一个异常</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```python</span><br><span class="line">&gt;&gt;&gt; requests.get(&#x27;http://github.com&#x27;, timeout=0.001)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">requests.exceptions.Timeout: HTTPConnectionPool(host=&#x27;github.com&#x27;, port=80): Request timed out. (timeout=0.001)</span><br></pre></td></tr></table></figure>

<p><strong>cookies</strong></p>
<p>要在请求中传入Cookies，只需准备一个dict传入<code>cookies</code>参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cs = &#123;<span class="string">&#x27;token&#x27;</span>: <span class="string">&#x27;12345&#x27;</span>, <span class="string">&#x27;status&#x27;</span>: <span class="string">&#x27;working&#x27;</span>&#125;</span><br><span class="line">r = requests.get(url, cookies=cs)</span><br></pre></td></tr></table></figure>

<p><strong>使用session</strong></p>
<p>Session会自动保存所有请求的cookie，创建后用法与request相同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session = requests.Session()</span><br><span class="line">response = session.get(<span class="string">&#x27;http:xxx&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p>retring</p>
<p>session  通过session自动保存cookies</p>
<h3 id="数据提取方法"><a href="#数据提取方法" class="headerlink" title="数据提取方法"></a>数据提取方法</h3><p>Json   </p>
<p>json.load 将json字符串转化为字典</p>
<p>json dumps 将字典转化为json字符串</p>
<p>参数：</p>
<p>ensure_assccii：优先转化成ascii码     indent：换行空格效果</p>
<p>实现爬取百度翻译结果</p>
<p>手机版网页简单</p>
<p>callback字段没用，直接删掉</p>
<h4 id="XPath"><a href="#XPath" class="headerlink" title="XPath"></a>XPath</h4><p>XPath是一门在XML文档中提取信息的语言，使用特别简便。</p>
<p><strong>提取方法：</strong></p>
<ul>
<li>使用<code>/</code>与<code>//</code>组合，通过路径提取元素</li>
<li>使用@属性名提取属性</li>
<li>使用@属性名=属性提取元素</li>
</ul>
<p><strong>函数：</strong></p>
<ul>
<li>start-with、end-with函数</li>
<li>contains函数</li>
<li>and</li>
<li>text()  返回元素的文本内容</li>
</ul>
<p><strong>技巧</strong></p>
<ul>
<li><p>二次提取，第一次提取一个元素，第二次在该元素的基础上进行提取，提取路径前要加上<code>&#39;.&#39;</code>，否则会再次从头开始提取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> res_xpath.xpath(<span class="string">&quot;//div[@id=&#x27;content&#x27;]//ul[@class=&#x27;list-col list-col5 list-express slide-item&#x27;]&quot;</span>):</span><br><span class="line">    <span class="keyword">for</span> books <span class="keyword">in</span> page.xpath(<span class="string">&#x27;./li&#x27;</span>):</span><br><span class="line">    <span class="comment"># 加点表示从上一级提取的位置开始查找</span></span><br></pre></td></tr></table></figure></li>
<li><p>安装XPath helper后可以复制路径，复制的路径最好不要使用*，代价较大，用具体的数据代替</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//*[@<span class="built_in">id</span>=<span class="string">&#x27;content&#x27;</span>]	 <span class="comment">#复制结果</span></span><br><span class="line">//div[@<span class="built_in">id</span>=<span class="string">&#x27;content&#x27;</span>] <span class="comment">#修改后</span></span><br></pre></td></tr></table></figure></li>
<li><p>若结果中包含大量空格换行，使用字符串的<code>strip()</code>函数去除</p>
</li>
<li><p>xpath可以进行逻辑判断</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/button[@value=<span class="string">&#x27;submit&#x27;</span> <span class="keyword">or</span> @name=<span class="string">&#x27;tijiao&#x27;</span>]</span><br></pre></td></tr></table></figure></li>
<li><p>若提取到的数据是列表，需要取列表中的具体元素</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">book[<span class="string">&#x27;title&#x27;</span>] = books.xpath(<span class="string">&quot;./div[@class=&#x27;cover&#x27;]/a/@title&quot;</span>)[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></li>
<li><p>保存爬取的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法一 借助json保存 后两个参数的作用分别为换行保存与使用合适的编码方式</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;douban.txt&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json.dumps(result_dict, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line">    </span><br><span class="line"><span class="comment">#方法二 直接保存</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;douban.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> film <span class="keyword">in</span> films:</span><br><span class="line">        f.write(<span class="built_in">str</span>(film))</span><br><span class="line">        f.write(<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>对字符串进行匹配，正则表达式规则较多，使用时慢慢熟练即可</p>
<p>####正则表达式规则</p>
<p>常用（.*?）来匹配任意长度的字符，如提取网址，？为非贪婪匹配</p>
<p><img src="http://qiniu.cuiqingcai.com/wp-content/uploads/2015/02/20130515113723855-e1424095177180.png" alt="20130515113723855"></p>
<h4 id="re模块"><a href="#re模块" class="headerlink" title="re模块"></a>re模块</h4><p>python自带re模块，提供了对正则表达式的支持，主要用到的方法如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回pattern对象</span></span><br><span class="line">re.<span class="built_in">compile</span>(string[,flag])  </span><br><span class="line"><span class="comment">#以下为匹配所用函数</span></span><br><span class="line">re.match(pattern, string[, flags])</span><br><span class="line">re.search(pattern, string[, flags])</span><br><span class="line">re.split(pattern, string[, maxsplit])</span><br><span class="line">re.findall(pattern, string[, flags])</span><br><span class="line">re.finditer(pattern, string[, flags])</span><br><span class="line">re.sub(pattern, repl, string[, count])</span><br><span class="line">re.subn(pattern, repl, string[, count])</span><br></pre></td></tr></table></figure>

<p><strong>pattern</strong></p>
<p>pattern理解为匹配模式，创建方法如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;str&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>flag</strong></p>
<p>flag是匹配模式，含义如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">re.I(全拼：IGNORECASE): 忽略大小写（括号内是完整写法，下同）</span><br><span class="line">re.M(全拼：MULTILINE): 多行模式，改变&#x27;^&#x27;和&#x27;$&#x27;的行为（参见上图）</span><br><span class="line">re.S(全拼：DOTALL): 点任意匹配模式，改变&#x27;.&#x27;的行为</span><br><span class="line">re.L(全拼：LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定</span><br><span class="line">re.U(全拼：UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性</span><br><span class="line">re.X(全拼：VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。</span><br></pre></td></tr></table></figure>

<p><strong>re.match(pattern, string[, flags]) 方法</strong></p>
<p>从开头开始匹配，匹配成功返回一个<strong>匹配对象</strong>，若匹配不成功返回null，pattern结束时不再向后匹配</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pattern=re.<span class="built_in">compile</span>(<span class="string">r&#x27;hello&#x27;</span>)</span><br><span class="line"></span><br><span class="line">result=re.match(pattern,<span class="string">&#x27;hello&#x27;</span>)		 <span class="comment"># -&gt;hello</span></span><br><span class="line">result=re.match(pattern,<span class="string">&#x27;hell&#x27;</span>)			 <span class="comment"># -&gt;null</span></span><br><span class="line">result=re.match(pattern,<span class="string">&#x27;hello world&#x27;</span>)	 <span class="comment"># -&gt;hello</span></span><br></pre></td></tr></table></figure>

<p><strong>re.search(pattern, string[, flags]) 方法</strong><br>从任意位置开始匹配，匹配成功返回一个匹配对象，匹配不成功返回null</p>
<p><strong>re.spilt(pattern, string[, maxsplit]) 方法</strong></p>
<p>按照能够匹配的子串将string分割后返回列表</p>
<p>maxsplit指定最大分割次数，不指定将全部分割</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pattern=re.<span class="built_in">compile</span>(<span class="string">r&#x27;\d+&#x27;</span>)	<span class="comment">#\d为数字</span></span><br><span class="line">re.split(pattern,<span class="string">&#x27;one1two2three3four4&#x27;</span>)</span><br><span class="line"><span class="comment"># -&gt;[&#x27;one&#x27;,&#x27;two&#x27;,&#x27;three&#x27;,&#x27;four&#x27;,&#x27;&#x27;]</span></span><br></pre></td></tr></table></figure>

<p><strong>re.findall(pattern, string[, flags])</strong></p>
<p>搜索string，以列表形式返回全部能匹配的字串</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pattern=re.<span class="built_in">compile</span>(<span class="string">r&#x27;\d+&#x27;</span>)</span><br><span class="line">re.split(pattern,<span class="string">&#x27;one1two2three3four4&#x27;</span>)</span><br><span class="line"><span class="comment"># -&gt;[&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;4&#x27;]</span></span><br></pre></td></tr></table></figure>

<p><strong>re.finditer(pattern, string[, flags])</strong></p>
<p>与<strong>findal() 方法</strong>类似，返回的结果不是列表而是迭代器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;\d+&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> re.finditer(pattern,<span class="string">&#x27;one1two2three3four4&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span> m.group(),</span><br><span class="line"> </span><br><span class="line"><span class="comment">### 输出 ###</span></span><br><span class="line"><span class="comment"># 1 2 3 4</span></span><br></pre></td></tr></table></figure>

<p><strong>匹配对象的方法</strong></p>
<p>上述re模块函数返回内容分为两种，返回匹配对象后者返回匹配列表</p>
<p>常用的匹配对象方法有<code>group()</code> <code>groups()</code>、还有关于位置的<code>start()</code> <code>end()</code> <code>span()</code></p>
<p><strong>group([group1..]) 方法</strong> </p>
<p>返回整个的匹配对象，在pattern依据分组<code>()</code>分割</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pattern=re.<span class="built_in">compile</span>(<span class="string">r&#x27;(\w+)\+(\w+)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">re.match(pattern,<span class="string">&#x27;我12345+abcde&#x27;</span>).group()	<span class="comment"># -&gt;&#x27;我12345+abcde&#x27;</span></span><br><span class="line">re.match(pattern,<span class="string">&#x27;我12345+abcde&#x27;</span>).group(<span class="number">1</span>)	<span class="comment"># -&gt;&#x27;我12345&#x27;</span></span><br><span class="line">re.match(pattern,<span class="string">&#x27;我12345+abcde&#x27;</span>).group(<span class="number">2</span>)	<span class="comment"># -&gt;&#x27;abcde&#x27;</span></span><br></pre></td></tr></table></figure>

<p>分组不仅仅得到想得到匹配的整个字符串，还能得到整个字符串里的特定字符串</p>
<p><strong>groups() 方法</strong></p>
<p>返回一个含有所有匹配子组的元组，匹配失败返回空元组</p>
<p>html响应与elements可能不一样，以html响应为准</p>
<h3 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h3><ul>
<li>首先应查看请求中有无对应的数据，从preview中查看</li>
<li>xpath爬取静态网页，动态网页获取json</li>
<li>手机版网页简单，爬取容易</li>
<li>获取json的请求可修改参数</li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2021-05-29</span><i class="fa fa-tag"></i><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,http://example.com/2021/05/29/Python爬虫/,Dong,Python爬虫笔记,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2021/05/29/matlab%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/" title="matlab笔记">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2021/05/29/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Linux常用命令">下一篇</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'WhMbDnysmoUsvuwwcVsbbMzI-gzGzoHsz',
  app_key:'8kGxneBiHdCHPVNPRLaw2aO2',
  placeholder:'如果您有问题,欢迎评论,请填写正确的联系方式≧◉◡◉≦',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'retro'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>